# community/src/migrate_csv_to_db.py
import os
import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch
import hashlib
from datetime import datetime
from logger import setup_logger  # ê¸°ì¡´ logger.py ì‚¬ìš©

def migrate_csv_to_db(csv_dir, db_config, logger):
    """
    CSV íŒŒì¼ë“¤ì„ Postgres DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
    :param csv_dir: CSV íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ì˜ˆ: /app/data)
    :param db_config: Postgres ì—°ê²° ì •ë³´
    :param logger: ë¡œê¹… ê°ì²´
    """
    logger.info("ğŸš€ CSV to DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
    
    # DB ì—°ê²°
    try:
        conn = psycopg2.connect(**db_config)
        cur = conn.cursor()
        logger.info("âœ… DB ì—°ê²° ì„±ê³µ")
    except Exception as e:
        logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # CSV íŒŒì¼ ëª©ë¡
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith('202508.csv')]
    logger.info(f"ğŸ“‚ ë°œê²¬ëœ CSV íŒŒì¼: {csv_files}")
    
    for csv_file in csv_files:
        try:
            logger.info(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {csv_file}")
            filepath = os.path.join(csv_dir, csv_file)
            
            # CSV ì½ê¸°
            df = pd.read_csv(filepath, encoding='utf-8')
            logger.info(f"ğŸ“Š {csv_file}ì—ì„œ {len(df)} í–‰ ì½ìŒ")
            
            # ë°ì´í„° ì¤€ë¹„
            prepared_comments = []
            for _, row in df.iterrows():
                try:
                    # time íŒŒì‹± (í˜•ì‹: "20 Aug, 2025 12:49 PM")
                    comment_time = datetime.strptime(row['time'], '%d %b, %Y %I:%M %p')
                    comment_text = str(row['text']).strip()
                    stock_symbol = str(row['stock_symbol']).strip()
                    comment_hash = hashlib.md5(comment_text.encode()).hexdigest()
                    
                    prepared_comments.append((
                        stock_symbol,
                        comment_time,
                        comment_text,
                        comment_hash
                    ))

                except Exception as e:
                    logger.warning(f"âš ï¸ í–‰ ì²˜ë¦¬ ì˜¤ë¥˜ (ìŠ¤í‚µ): {e}")
                    continue
            
            # Batch UPSERT
            upsert_query = """
            INSERT INTO comments (stock_symbol, comment_time, comment_text, comment_hash)
            VALUES (%s, %s, %s, %s)
            ON CONFLICT (stock_symbol, comment_time, comment_hash)
            DO UPDATE SET comment_text = EXCLUDED.comment_text;
            """
            
            execute_batch(cur, upsert_query, prepared_comments, page_size=1000)
            conn.commit()
            logger.info(f"âœ… {csv_file}: {len(prepared_comments)} í–‰ DBì— UPSERT ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ {csv_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            conn.rollback()
            continue
    
    # ì •ë¦¬
    cur.close()
    conn.close()
    logger.info("ğŸ‰ ëª¨ë“  CSV íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logger = setup_logger("migrate_csv_to_db", "/app/logs")
    
    # DB ì„¤ì • (docker-composeì™€ ì¼ì¹˜)
    db_config = {
        "dbname": "stockmind",
        "user": "user",
        "password": "password",
        "host": "db",  # docker-compose ì„œë¹„ìŠ¤ ì´ë¦„
        "port": "5432"
    }
    
    # CSV ë””ë ‰í† ë¦¬
    csv_dir = "/app/data"
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrate_csv_to_db(csv_dir, db_config, logger)