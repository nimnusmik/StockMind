# community/src/crawler.py
import random
import time
from datetime import datetime
import os
import pandas as pd
from playwright.sync_api import sync_playwright
from config import stocks, output_dir, logs_base_dir, user_agents, cutoff_date
from logger import setup_logger
from utils import wait_for_element, wait_for_comments_frame, scroll_and_wait, is_after_cutoff

class MultiStockYahooFinanceCrawler:
    def __init__(self, headless=True, proxy_list=None):
        self.headless = headless
        self.cutoff_date = cutoff_date
        self.playwright = sync_playwright().start()
        self.stocks = stocks
        self.output_dir = output_dir
        self.logs_base_dir = logs_base_dir
        self.proxy_list = proxy_list
        
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.logs_base_dir, exist_ok=True)
        
        self.browser = self.playwright.chromium.launch(
            headless=headless,
            args=[
                '--no-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
        )
        
        self.context = None
        self.page = None
        self.setup_context()

    def setup_context(self):
        if self.context:
            self.context.close()
        self.context = self.browser.new_context(
            user_agent=random.choice(user_agents),
            viewport={"width": 1920, "height": 1080},
            ignore_https_errors=True,
            java_script_enabled=True,
            proxy=random.choice(self.proxy_list) if self.proxy_list else None
        )
        self.page = self.context.new_page()
        self.page.set_default_timeout(30000)

    def sort_comments_by_newest(self, target_frame, logger):
        try:
            if not wait_for_element(target_frame, '#spotim-sort-by'):
                logger.info("âŒ Sort by ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False

            button = target_frame.query_selector('#spotim-sort-by')
            button.scroll_into_view_if_needed()
            button.click()
            logger.info("ğŸ”„ ì •ë ¬ ë“œë¡­ë‹¤ìš´ ì—´ê¸°...")
            
            time.sleep(random.uniform(2, 5))
            
            newest_button = target_frame.locator('text="Newest"').first
            if newest_button.is_visible():
                newest_button.click()
                logger.info("âœ… Newest ë²„íŠ¼ í´ë¦­ ì„±ê³µ!")
                time.sleep(random.uniform(2, 5))
                return True
            else:
                logger.info("âŒ Newest ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
        except Exception as e:
            logger.info(f"âŒ ì •ë ¬ ì˜¤ë¥˜: {e}")
            return False

    def load_more_comments(self, target_frame, logger, stock_symbol):
        try:
            logger.info("ğŸ” Show More ë²„íŠ¼ íƒìƒ‰ ì‹œì‘...")
            initial_comment_count = len(target_frame.query_selector_all('li[aria-label="Comment"]'))
            logger.info(f"ğŸ“Š í˜„ì¬ ëŒ“ê¸€ ìˆ˜: {initial_comment_count}")
            
            logger.info("ğŸ”„ í˜ì´ì§€ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤...")
            scroll_and_wait(target_frame, 1000, logger)
            
            button_patterns = [
                'text="Show More Comments"', 'text="Show more comments"', 
                'text="Show More"', 'text="Load More"', 'text="Load more"',
                'text="More Comments"', 'text="See more comments"',
                '[aria-label*="more"]', '[aria-label*="More"]',
                '[title*="more"]', '[title*="More"]',
            ]
            
            for attempt in range(3):
                for pattern in button_patterns:
                    try:
                        logger.info(f"ğŸ” íŒ¨í„´ ì‹œë„: {pattern} (ì‹œë„ {attempt+1})")
                        more_button = target_frame.locator(pattern).first
                        if more_button.is_visible():
                            logger.info(f"âœ… '{pattern}' ë²„íŠ¼ ë°œê²¬!")
                            more_button.scroll_into_view_if_needed()
                            time.sleep(random.uniform(1, 3))
                            before_click_count = len(target_frame.query_selector_all('li[aria-label="Comment"]'))
                            more_button.click()
                            logger.info("ğŸ–±ï¸ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
                            time.sleep(random.uniform(3, 7))
                            after_click_count = len(target_frame.query_selector_all('li[aria-label="Comment"]'))
                            if after_click_count > before_click_count:
                                logger.info(f"ğŸ‰ ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ìƒˆ ëŒ“ê¸€ ë¡œë”©: {before_click_count} -> {after_click_count}")
                                return True
                            else:
                                logger.info(f"âš ï¸ ë²„íŠ¼ í´ë¦­í–ˆì§€ë§Œ ëŒ“ê¸€ ìˆ˜ ë³€í™” ì—†ìŒ: {before_click_count}")
                    except Exception as e:
                        logger.info(f"âš ï¸ {pattern} íŒ¨í„´ ì‹¤íŒ¨: {e}")
                        continue
                if attempt < 2:
                    logger.info(f"ğŸ”„ ë²„íŠ¼ ì°¾ê¸° ì¬ì‹œë„ {attempt+2}...")
                    time.sleep(random.uniform(5, 10))
            return False
        except Exception as e:
            logger.info(f"âš ï¸ Show More ë²„íŠ¼ ì°¾ê¸° ì „ì²´ ì˜¤ë¥˜: {e}")
            return False

    def collect_comments_optimized(self, target_frame, stock_symbol, sort_success=True, logger=None):
        collected = []
        seen_ids = set()
        consecutive_old_comments = 0
        max_consecutive_old = 10 if not sort_success else 5
        last_processed_index = 0
        batch_size = 50
        no_new_comments_count = 0
        max_no_new_comments = 10
        rounds = 0
        
        logger.info("ğŸš€ ìµœì í™”ëœ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘...")
        logger.info(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}, ìµœëŒ€ ì—°ì† ì˜¤ë˜ëœ ëŒ“ê¸€: {max_consecutive_old}")
        
        while rounds < 500:
            rounds += 1
            logger.info(f"\nğŸ”„ ë¼ìš´ë“œ {rounds}")
            
            all_comments = target_frame.query_selector_all('li[aria-label="Comment"]')
            total_comments = len(all_comments)
            logger.info(f"ğŸ“‹ ì´ ëŒ“ê¸€ ìˆ˜: {total_comments}")
            
            new_comments = all_comments[last_processed_index:]
            if not new_comments:
                logger.info("â³ ìƒˆ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤. Show More ì‹œë„...")
                no_new_comments_count += 1
                if no_new_comments_count >= max_no_new_comments:
                    logger.info(f"ğŸ’€ ì—°ì† {no_new_comments_count}ë²ˆ ìƒˆ ëŒ“ê¸€ ì—†ìŒ, ìˆ˜ì§‘ ì¢…ë£Œ")
                    break
            else:
                logger.info(f"ğŸ†• ìƒˆ ëŒ“ê¸€ {len(new_comments)}ê°œ ì²˜ë¦¬ ì¤‘...")
                no_new_comments_count = 0
                
                for i, comment in enumerate(new_comments[:batch_size]):
                    try:
                        time_tag = comment.query_selector('time[data-spot-im-class="message-timestamp"]')
                        text_tag = comment.query_selector('div[data-spot-im-class="message-text"]')
                        if not time_tag or not text_tag:
                            continue
                        time_str = time_tag.get_attribute('title')
                        text_str = text_tag.inner_text().strip()
                        if not time_str or not text_str:
                            continue
                        comment_id = f"{time_str}_{hash(text_str)}"
                        if comment_id in seen_ids:
                            continue
                        seen_ids.add(comment_id)
                        if is_after_cutoff(time_str, self.cutoff_date):
                            collected.append({"time": time_str, "text": text_str})
                            logger.info(f"âœ… ìˆ˜ì§‘ ({len(collected)}): {time_str}")
                            consecutive_old_comments = 0
                        else:
                            consecutive_old_comments += 1
                            logger.info(f"â° ì˜¤ë˜ëœ ëŒ“ê¸€: {time_str} ({consecutive_old_comments})")
                            if consecutive_old_comments >= max_consecutive_old:
                                logger.info("ğŸ’€ ì—°ì†ìœ¼ë¡œ ì˜¤ë˜ëœ ëŒ“ê¸€ ë°œê²¬, ìˆ˜ì§‘ ì¤‘ë‹¨")
                                return collected
                    except Exception as e:
                        logger.info(f"âš ï¸ ëŒ“ê¸€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
                
                last_processed_index = min(last_processed_index + batch_size, total_comments)
                logger.info(f"ğŸ“ˆ ì²˜ë¦¬ ì§„í–‰ë¥ : {last_processed_index}/{total_comments}")
                
                # Intermediate saving
                if len(collected) > 0 and len(collected) % 100 == 0:
                    current_month = datetime.now().strftime("%Y%m")
                    temp_filename = f"{stock_symbol}_comments_{current_month}_temp_{len(collected)}.csv"
                    temp_filepath = os.path.join(self.output_dir, temp_filename)
                    df = pd.DataFrame(collected)
                    df.to_csv(temp_filepath, index=False, encoding='utf-8')
                    logger.info(f"ğŸ“ ì¤‘ê°„ ì €ì¥: {temp_filepath}")

            
            
            if not self.load_more_comments(target_frame, logger, stock_symbol):
                logger.info("ğŸ“„ ë” ì´ìƒ ëŒ“ê¸€ ë¡œë”© ë¶ˆê°€")
                if no_new_comments_count == 0:
                    continue
                else:
                    break
                
            if rounds % 10 == 0:
                logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
                target_frame.evaluate("if (window.gc) window.gc();")
                time.sleep(random.uniform(1, 3))
        
        return collected

    def navigate_to_stock_page(self, stock_symbol, logger):
        urls_to_try = [
            f"https://finance.yahoo.com/quote/{stock_symbol}/community/",
            f"https://finance.yahoo.com/quote/{stock_symbol}/",
        ]
        
        for i, url in enumerate(urls_to_try):
            for attempt in range(3):
                try:
                    logger.info(f"ğŸ”„ ì‹œë„ {i+1}, ì¬ì‹œë„ {attempt+1}: {url}")
                    self.page.goto(url, timeout=90000, wait_until="domcontentloaded")
                    wait_for_element(self.page, 'body')
                    logger.info(f"âœ… í˜ì´ì§€ ë¡œë”© ì„±ê³µ: {url}")
                    
                    if "community" not in url:
                        logger.info("ğŸ”„ ì»¤ë®¤ë‹ˆí‹° í˜ì´ì§€ë¡œ ì´ë™...")
                        community_link = self.page.locator('text="Community"').first
                        if community_link.is_visible(timeout=5000):
                            community_link.click()
                            self.page.wait_for_url("**/community/**", timeout=30000)
                        else:
                            self.page.goto(f"https://finance.yahoo.com/quote/{stock_symbol}/community/", 
                                         timeout=60000, wait_until="domcontentloaded")
                    return True
                except Exception as e:
                    logger.info(f"âŒ {url} ë¡œë”© ì‹¤íŒ¨: {e}")
                    if attempt < 2:
                        logger.info(f"ğŸ”„ ì¬ì‹œë„ {attempt+2}...")
                        time.sleep(random.uniform(5, 10))
                    continue
            if i < len(urls_to_try) - 1:
                logger.info("ğŸ”„ ë‹¤ë¥¸ URLë¡œ ì¬ì‹œë„...")
                time.sleep(random.uniform(5, 10))
        return False

    def crawl_stock_comments(self, stock_symbol):
        logger = setup_logger(stock_symbol, self.logs_base_dir)
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ¯ {stock_symbol} ëŒ“ê¸€ í¬ë¡¤ë§ ì‹œì‘...")
        logger.info(f"{'='*60}")
        
        self.setup_context()  # New context with random user agent
        if not self.navigate_to_stock_page(stock_symbol, logger):
            logger.info(f"âŒ {stock_symbol} í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")
            return None
        
        logger.info("â³ í˜ì´ì§€ ì•ˆì •í™” ëŒ€ê¸°...")
        self.page.evaluate("window.scrollBy(0, 400);")
        time.sleep(random.uniform(3, 7))
        
        try:
            self.page.wait_for_load_state("networkidle", timeout=15000)
            logger.info("âœ… ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™” ì™„ë£Œ")
        except:
            logger.info("âš ï¸ ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ, ê³„ì† ì§„í–‰")
        
        target_frame = wait_for_comments_frame(self.page, logger=logger)
        if not target_frame:
            logger.info(f"âŒ {stock_symbol} ëŒ“ê¸€ í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        sort_success = self.sort_comments_by_newest(target_frame, logger)
        if sort_success:
            logger.info("ğŸ‰ ìµœì‹ ìˆœ ì •ë ¬ ì„±ê³µ!")
        else:
            logger.info("âš ï¸ ì •ë ¬ ì‹¤íŒ¨, ëª¨ë“  ëŒ“ê¸€ì„ í™•ì¸í•©ë‹ˆë‹¤...")
        
        start_time = time.time()
        comments = self.collect_comments_optimized(target_frame, stock_symbol, sort_success, logger)
        end_time = time.time()
        
        logger.info(f"\nğŸŠ {stock_symbol} ì´ {len(comments)}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"â±ï¸ ìˆ˜ì§‘ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        
        if comments:
            current_month = datetime.now().strftime("%Y%m")
            filename = f"{stock_symbol}_comments_{current_month}.csv"
            filepath = os.path.join(self.output_dir, filename)
            for comment in comments:
                comment['stock_symbol'] = stock_symbol
            df = pd.DataFrame(comments)
            df.to_csv(filepath, index=False, encoding='utf-8')
            logger.info(f"ğŸ“ ëŒ“ê¸€ì´ '{filepath}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            logger.info(f"\nğŸ“Š {stock_symbol} ìˆ˜ì§‘ í†µê³„:")
            logger.info(f"   - ì´ ëŒ“ê¸€ ìˆ˜: {len(comments)}")
            logger.info(f"   - ë¶„ë‹¹ ìˆ˜ì§‘ë¥ : {len(comments) / ((end_time - start_time) / 60):.1f}ê°œ/ë¶„")
            logger.info(f"   - ìµœì‹  ëŒ“ê¸€: {comments[0]['time'] if comments else 'N/A'}")
            logger.info(f"   - ê°€ì¥ ì˜¤ë˜ëœ ëŒ“ê¸€: {comments[-1]['time'] if comments else 'N/A'}")
            
            return comments
        else:
            logger.info(f"âš ï¸ {stock_symbol} ìˆ˜ì§‘ëœ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def crawl_all_stocks(self):
        logger = setup_logger('crawl_all', self.logs_base_dir)
        logger.info(f"\nğŸš€ ë‹¤ì¤‘ ì£¼ì‹ ëŒ“ê¸€ í¬ë¡¤ë§ ì‹œì‘!")
        logger.info(f"ğŸ“‹ ëŒ€ìƒ ì¢…ëª©: {', '.join(self.stocks)}")
        logger.info(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {self.output_dir}")
        
        total_start_time = time.time()
        all_results = {}
        
        for i, stock in enumerate(self.stocks, 1):
            logger.info(f"\nğŸ”„ ì§„í–‰ë¥ : {i}/{len(self.stocks)} ({i/len(self.stocks)*100:.1f}%)")
            try:
                comments = self.crawl_stock_comments(stock)
                all_results[stock] = len(comments) if comments else 0
                if i < len(self.stocks):
                    logger.info(f"â³ ë‹¤ìŒ ì¢…ëª©ê¹Œì§€ ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
                    time.sleep(random.uniform(5, 10))
            except KeyboardInterrupt:
                logger.info(f"\nğŸ›‘ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤ ({stock}ì—ì„œ)")
                break
            except Exception as e:
                logger.info(f"âŒ {stock} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                all_results[stock] = 0
                continue
        
        total_end_time = time.time()
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ‰ ëª¨ë“  ì£¼ì‹ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"{'='*80}")
        logger.info(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_end_time - total_start_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
        
        total_comments = 0
        for stock, count in all_results.items():
            status = "âœ…" if count > 0 else "âŒ"
            logger.info(f"   {status} {stock}: {count}ê°œ")
            total_comments += count
        
        logger.info(f"\nğŸ“ˆ ì´ ìˆ˜ì§‘ ëŒ“ê¸€ ìˆ˜: {total_comments}ê°œ")
        logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
        return all_results

    def close(self):
        self.context.close()
        self.browser.close()
        self.playwright.stop()
