import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time, datetime, traceback

def get_article_content(driver, url):
    try:
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'p.yf-1090901'))
        )
        soup = BeautifulSoup(driver.page_source, 'html.parser')

        paragraphs = soup.select('p.yf-1090901')
        content = ' '.join([p.get_text(strip=True) for p in paragraphs]) if paragraphs else 'ë³¸ë¬¸ ì—†ìŒ'

        time_tag = soup.select_one('time.byline-attr-meta-time')
        if time_tag and time_tag.has_attr('datetime'):
            utc_time_tag = time_tag['datetime']
            utc_time = datetime.datetime.fromisoformat(utc_time_tag.replace('Z', '+00:00'))
            kst_time = utc_time + datetime.timedelta(hours=9)
            if kst_time.hour >= 6:
                kst_time += datetime.timedelta(days=1)
            date_str = kst_time.strftime('%Y-%m-%d')
        else:
            date_str = datetime.datetime.now().strftime('%Y-%m-%d')

        return content, date_str

    except Exception as e:
        print(f"â— ì¬ì‹œë„ ì‹¤íŒ¨ ({url}): {e}")
        traceback.print_exc()
        return "ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨", datetime.datetime.now().strftime('%Y-%m-%d')

def retry_failed_articles(filename):
    df = pd.read_csv(filename)

    failed_indices = df[df['content'] == 'ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨'].index.tolist()
    if not failed_indices:
        print("âœ… ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ” ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨ëœ ë‰´ìŠ¤ {len(failed_indices)}ê±´ ì¬ì‹œë„ ì‹œì‘")

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    for i in failed_indices:
        row = df.loc[i]
        print(f"ğŸ”„ {i}ë²ˆ ë‰´ìŠ¤ ì¬ì‹œë„ ì¤‘ ...", end=" ")
        content, date = get_article_content(driver, row['url'])
        df.at[i, 'content'] = content
        df.at[i, 'date'] = date
        time.sleep(2)
        print("ì™„ë£Œ")

    driver.quit()
    df.to_csv(filename, index=False)
    print(f"âœ… ì¬ì‹œë„ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    tickers = ['AAPL', 'GOOG', 'META', 'TSLA', 'MSFT', 'AMZN', 'NVDA', 'NFLX']
    for ticker in tickers:
        print(f'â—ï¸ {ticker} ëŒ€ìƒ ìˆ˜ì§‘ ì‹¤íŒ¨í•œ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘')
        filename = f'../temp/{ticker}_temp.csv'
        retry_failed_articles(filename)
