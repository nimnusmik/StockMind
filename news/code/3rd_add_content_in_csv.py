import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import datetime

now = datetime.datetime.now(); now = now.strftime('%Y-%m-%d')

def get_article_content(driver, url):
    try:
        driver.get(url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, 'html.parser')

        paragraphs = soup.select('p.yf-1090901')
        content = ' '.join([p.get_text(strip=True) for p in paragraphs]) if paragraphs else 'ë³¸ë¬¸ ì—†ìŒ'
        time_tag = soup.select_one('time.byline-attr-meta-time')
        if time_tag and time_tag.has_attr('datetime'):
            utc_time_tag = time_tag['datetime']
            utc_time = datetime.datetime.fromisoformat(utc_time_tag.replace('Z', '+00:00'))
            kst_time = utc_time + datetime.timedelta(hours=9)

            if kst_time.hour >= 6:
                kst_time += datetime.timedelta(days=1)

            date_str = kst_time.strftime('%Y-%m-%d')
        else:
            date_str = datetime.datetime.now().strftime('%Y-%m-%d')

        return content, date_str

    except Exception as e:
        print(f"â— ë³¸ë¬¸ ë˜ëŠ” ë‚ ì§œ ìˆ˜ì§‘ ì‹¤íŒ¨ ({url}):", e)
        return "ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨", datetime.datetime.now().strftime('%Y-%m-%d')

def enrich_articles_with_content(filename):
    df = pd.read_csv(filename)

    if 'content' not in df.columns:
        df['content'] = ""

    options = Options()
    options.binary_location = "/usr/bin/google-chrome" # WSLì—ì„œ ì‹¤í–‰í•  ë•Œ ì ìš©
    options.add_argument("--blink-settings=imagesEnabled=false") # ë¶ˆí•„ìš”í•œ ê´‘ê³ /ì´ë¯¸ì§€ ì•ˆ ë¶ˆëŸ¬ì˜¤ë„ë¡
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920x1080")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    i = 0
    while i < len(df):
        row = df.iloc[i]
        if isinstance(row['content'], str) and row['content'].strip():
            print(f"ğŸ›‘ {i}ë²ˆì§¸ ì´í›„ëŠ” ì´ë¯¸ ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ â†’ ì¤‘ë‹¨")
            break

        print(f"âœ… {i}ë²ˆ ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘ ...", end = " ")
        content, date = get_article_content(driver, row['url'])
        df.at[i, 'content'] = content
        df.at[i, 'date'] = date
        time.sleep(1)
        print(f"ì™„ë£Œ")
        i += 1

    driver.quit()
    df.to_csv(filename, index=False)
    print(f"âœ… ë³¸ë¬¸ì´ í¬í•¨ëœ ë‰´ìŠ¤ {i}ê±´ì´ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    tickers = ['AAPL', 'GOOG', 'META', 'TSLA', 'MSFT', 'AMZN', 'NVDA', 'NFLX']
    for ticker in tickers:
        print(f'â—ï¸ {ticker} ëŒ€ìƒ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘')
        filename = f'../temp/{ticker}_temp.csv'
        enrich_articles_with_content(filename)
